# <div align="center">Argus Web Crawler | ç½‘é¡µçˆ¬è™«å·¥å…·</div>

<div align="center">

[![License](https://img.shields.io/github/license/BreCaspian/argus-crawler?color=blue&style=flat-square)](https://github.com/BreCaspian/argus-crawler/blob/main/LICENSE)
[![Node Version](https://img.shields.io/badge/node-%3E%3D14.0.0-brightgreen?style=flat-square)](https://nodejs.org)
[![Platform](https://img.shields.io/badge/platform-windows%20%7C%20macos%20%7C%20linux-lightgrey?style=flat-square)](https://github.com/BreCaspian/argus-crawler)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](https://github.com/BreCaspian/argus-crawler/pulls)
[![Last Commit](https://img.shields.io/github/last-commit/BreCaspian/argus-crawler?style=flat-square)](https://github.com/BreCaspian/argus-crawler/commits/main)

[ä¸­æ–‡](#ä¸­æ–‡) | [English](#english)

</div>

<a id="ä¸­æ–‡"></a>

## ğŸŒ ä¸­æ–‡

Argus æ˜¯ä¸€æ¬¾å…¨è‡ªåŠ¨ç½‘é¡µçˆ¬è™«å·¥å…·ï¼Œèƒ½å¤Ÿè‡ªåŠ¨ç»•è¿‡é˜²çˆ¬è™«ä¿æŠ¤ï¼Œä¿æŠ¤çˆ¬å–è€…éšç§ï¼Œå¹¶å°†å†…å®¹è½¬æ¢ä¸º Markdown æˆ– XLSX æ ¼å¼ã€‚

### âš¡ å¿«é€Ÿå¼€å§‹

#### æ–¹æ³•ä¸€ï¼šç›´æ¥å®‰è£…

```bash
# å…‹éš†ä»“åº“æˆ–ä¸‹è½½é¡¹ç›®åˆ°æœ¬åœ°
git clone https://github.com/BreCaspian/argus-crawler.git
cd argus-crawler

# å®‰è£…ä¾èµ–
npm install

# åŸºæœ¬ç”¨æ³•
node argus.js https://example.com
```

#### æ–¹æ³•äºŒï¼šä½¿ç”¨npm CLI

```bash
# å®‰è£…å…¨å±€åŒ…
npm install -g argus-crawler

# åŸºæœ¬ç”¨æ³•
argus https://example.com

# ä½¿ç”¨é«˜çº§æ¨¡å¼å’Œä»£ç†
argus https://example.com --advanced-mode --proxies proxies.txt
```

### âœ¨ ç‰¹æ€§

- **å…¨è‡ªåŠ¨çˆ¬å–**ï¼šåªéœ€è¾“å…¥èµ·å§‹ URLï¼Œè‡ªåŠ¨çˆ¬å–æ•´ä¸ªç½‘ç«™
- **åçˆ¬è™«æŠ€æœ¯**ï¼šè‡ªåŠ¨ç»•è¿‡ JavaScript æŒ‘æˆ˜ã€CAPTCHA å’Œæµè§ˆå™¨æŒ‡çº¹æ£€æµ‹
- **IP éšè—**ï¼šæ”¯æŒä»£ç†è½®æ¢å’Œç”¨æˆ·ä»£ç†è½®æ¢ï¼Œé¿å…è¢«å°ç¦
- **æ™ºèƒ½å†…å®¹æå–**ï¼šè‡ªåŠ¨æå–é¡µé¢ä¸»è¦å†…å®¹ï¼Œè¿‡æ»¤å™ªéŸ³
- **å¤šæ ¼å¼è¾“å‡º**ï¼šæ ¹æ®å†…å®¹ç‰¹æ€§è‡ªåŠ¨é€‰æ‹© Markdownã€XLSX æˆ–æ··åˆæ ¼å¼
- **ç»“æ„åŒ–å­˜å‚¨**ï¼šæŒ‰ç…§ç½‘ç«™æ¶æ„ç»„ç»‡æ–‡ä»¶ï¼Œä¾¿äºæŸ¥æ‰¾å’Œç®¡ç†
- **éšç§ä¿æŠ¤**ï¼šåŠ å¯†æ—¥å¿—è®°å½•ï¼Œä¿æŠ¤ç”¨æˆ·éšç§
- **é«˜çº§æ€§èƒ½æ¨¡å¼**ï¼šæä¾›æ›´é«˜æ€§èƒ½çš„çˆ¬å–é€‰é¡¹å’Œå¢å¼ºçš„åŒ¿åæ€§
- **è·¨å¹³å°æ”¯æŒ**ï¼šå…¼å®¹ Windowsã€macOS å’Œ Linux ç³»ç»Ÿ

### ğŸ“„ é¡¹ç›®æ¶æ„

```
argus-crawler/
â”œâ”€â”€ src/                      # æ ¸å¿ƒæºä»£ç 
â”‚   â”œâ”€â”€ ArgusCrawler.js       # ä¸»çˆ¬è™«å®ç°
â”‚   â”œâ”€â”€ ProxyManager.js       # ä»£ç†ç®¡ç†å’Œè½®æ¢
â”‚   â””â”€â”€ utils.js              # å·¥å…·å‡½æ•°
â”œâ”€â”€ scripts/                  # æ”¯æŒè„šæœ¬
â”‚   â””â”€â”€ browser-setup.js      # æµè§ˆå™¨ç¯å¢ƒè®¾ç½®
â”œâ”€â”€ examples/                 # ä½¿ç”¨ç¤ºä¾‹
â”‚   â””â”€â”€ basic-usage.js        # åŸºæœ¬æ¼”ç¤º
â”œâ”€â”€ tests/                    # æµ‹è¯•æ–‡ä»¶
â”‚   â””â”€â”€ basic.test.js         # æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•
â”œâ”€â”€ argus.js                  # ä¸»æ‰§è¡Œæ–‡ä»¶
â”œâ”€â”€ package.json              # é¡¹ç›®å…ƒæ•°æ®
â”œâ”€â”€ README.md                 # æ–‡æ¡£
â””â”€â”€ LICENSE                   # MITè®¸å¯è¯
```

### ğŸš€ å®‰è£…

#### å‰ææ¡ä»¶

- Node.js 16.x æˆ–æ›´é«˜ç‰ˆæœ¬
- npm æˆ– yarn åŒ…ç®¡ç†å™¨

#### å®‰è£…æ–¹æ³•

**ä»GitHubå…‹éš†**

```bash
git clone https://github.com/BreCaspian/argus-crawler.git
cd argus-crawler
npm install
```

#### æµè§ˆå™¨å¼•æ“å®‰è£…

Argus ä½¿ç”¨ Playwright ä½œä¸ºæµè§ˆå™¨å¼•æ“ã€‚åœ¨å®‰è£…ä¾èµ–åï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å°è¯•å®‰è£…æ‰€éœ€çš„æµè§ˆå™¨ã€‚å¦‚æœè‡ªåŠ¨å®‰è£…å¤±è´¥ï¼Œå¯ä»¥æ‰‹åŠ¨å®‰è£…ï¼š

```bash
# å®‰è£…æ‰€æœ‰æ”¯æŒçš„æµè§ˆå™¨
npx playwright install

# ä»…å®‰è£… Chromiumï¼ˆæ¨èï¼Œå ç”¨ç©ºé—´å°ï¼‰
npx playwright install chromium
   
# åœ¨Linuxä¸Šå¯èƒ½éœ€è¦é¢å¤–çš„ç³»ç»Ÿä¾èµ–
npx playwright install-deps
```

#### ä½¿å·¥å…·å¯æ‰§è¡Œï¼ˆä»…é€‚ç”¨äº Linux/macOSï¼‰

```bash
chmod +x argus.js
```

### ğŸ–¥ï¸ è·¨å¹³å°è¿è¡Œ

Argus å®Œå…¨å…¼å®¹æ‰€æœ‰ä¸»è¦æ“ä½œç³»ç»Ÿï¼š

- **Windows**ï¼š
  ```
  node argus.js <url> [é€‰é¡¹]
  ```

- **macOS**ï¼š
  ```
  ./argus.js <url> [é€‰é¡¹]
  # æˆ–
  node argus.js <url> [é€‰é¡¹]
  ```

- **Linux**ï¼š
  ```
  ./argus.js <url> [é€‰é¡¹]
  # æˆ–
  node argus.js <url> [é€‰é¡¹]
  ```

#### å¹³å°ç‰¹å®šè¯´æ˜

- **Windows**ï¼šåœ¨ Windows ä¸Šï¼Œå·¥å…·ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨é€‚å½“çš„æµè§ˆå™¨è·¯å¾„
- **macOS**ï¼šåœ¨ macOS ä¸Šï¼Œè®¿é—®æŸäº›ç³»ç»Ÿç›®å½•å¯èƒ½éœ€è¦é¢å¤–çš„æƒé™
- **Linux**ï¼šåœ¨ Linux ç³»ç»Ÿä¸Šï¼Œæµè§ˆå™¨è‡ªåŠ¨åŒ–å¯èƒ½éœ€è¦é¢å¤–çš„ä¾èµ–é¡¹ã€‚ä½¿ç”¨ `npx playwright install-deps` å®‰è£…æ‰€éœ€çš„ç³»ç»ŸåŒ…

### ğŸ“– åŸºæœ¬ç”¨æ³•

æœ€ç®€å•çš„ç”¨æ³•æ˜¯ç›´æ¥æä¾›ç›®æ ‡ç½‘ç«™ URLï¼š

```bash
node argus.js https://crawler-test.com
```

è¿™å°†ä½¿ç”¨é»˜è®¤è®¾ç½®çˆ¬å–ç½‘ç«™ï¼Œå¹¶å°†ç»“æœä¿å­˜åœ¨å½“å‰ç›®å½•çš„ `argus_data` æ–‡ä»¶å¤¹ä¸­ã€‚

### ğŸ› ï¸ å‘½ä»¤è¡Œå‚æ•°

| å‚æ•° | ç®€å†™ | æè¿° | é»˜è®¤å€¼ |
|------|------|------|--------|
| `--output-dir <path>` | `-o` | æŒ‡å®šè¾“å‡ºç›®å½• | `./argus_data` |
| `--proxies <file>` | `-p` | æŒ‡å®šä»£ç†åˆ—è¡¨æ–‡ä»¶ | æ—  |
| `--depth <number>` | `-d` | è®¾ç½®çˆ¬å–æ·±åº¦ï¼ˆ1è¡¨ç¤ºåªçˆ¬å–èµ·å§‹é¡µé¢åŠå…¶ç›´æ¥é“¾æ¥ï¼‰ | `1` |
| `--delay <ms>` | `-w` | è¯·æ±‚ä¹‹é—´çš„å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰ | `1000` |
| `--format <format>` | `-f` | è¾“å‡ºæ ¼å¼ (markdown/xlsx/html/auto) | `auto` |
| `--encrypt` | `-e` | åŠ å¯†è¾“å‡ºå†…å®¹ | `false` |
| `--key <key>` | `-k` | åŠ å¯†/è§£å¯†å¯†é’¥ | `argus-default-key` |
| `--advanced-mode` | `-a` | å¯ç”¨é«˜çº§æ€§èƒ½æ¨¡å¼ | `false` |
| `--test-proxies` | æ—  | åœ¨ä½¿ç”¨å‰æµ‹è¯•ä»£ç†çš„æœ‰æ•ˆæ€§ | `false` |
| `--max-concurrency <number>` | æ—  | æœ€å¤§å¹¶å‘è¯·æ±‚æ•° | `10` (æ ‡å‡†) / `25` (é«˜çº§) |
| `--max-requests <number>` | æ—  | æœ€å¤§è¯·æ±‚æ€»æ•° | `1000` (æ ‡å‡†) / `5000` (é«˜çº§) |
| `--navigation-timeout <ms>` | æ—  | é¡µé¢å¯¼èˆªè¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ | `60000` (æ ‡å‡†) / `120000` (é«˜çº§) |
| `--no-browser-check` | æ—  | è·³è¿‡æµè§ˆå™¨ä¾èµ–æ£€æŸ¥ | `false` |
| `--download-resources` | æ—  | ä¸‹è½½é¡µé¢èµ„æº(å›¾ç‰‡ç­‰) | `false` |
| `--max-file-size <MB>` | æ—  | ä¸‹è½½èµ„æºçš„æœ€å¤§æ–‡ä»¶å¤§å°(MB) | `10` |
| `--help`, `-h` | æ—  | æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯ | N/A |
| `--version`, `-v` | æ—  | æ˜¾ç¤ºç‰ˆæœ¬å· | N/A |

### ğŸ§° ç‰¹æ®Šå‘½ä»¤

Argus è¿˜æä¾›äº†ä¸€äº›ç‰¹æ®Šå‘½ä»¤ï¼š

```bash
# æµ‹è¯•ç¯å¢ƒå’Œä¾èµ–é¡¹
node argus.js test-env

# è§£å¯†å·²åŠ å¯†çš„æ–‡ä»¶
node argus.js decrypt <åŠ å¯†æ–‡ä»¶> --key <å¯†é’¥> --output <è¾“å‡ºæ–‡ä»¶>
```

### ğŸ“ ä½¿ç”¨ç¤ºä¾‹

#### ä½¿ç”¨ä»£ç†åˆ—è¡¨ï¼š

```bash
node argus.js https://crawler-test.com --proxies proxies.txt
```

ä»£ç†æ–‡ä»¶åº”è¯¥æ¯è¡ŒåŒ…å«ä¸€ä¸ªä»£ç†æœåŠ¡å™¨åœ°å€ï¼Œä¾‹å¦‚ï¼š`http://123.45.67.89:8080`ã€‚

#### é™åˆ¶çˆ¬å–æ·±åº¦ï¼š

```bash
node argus.js https://crawler-test.com --depth 2
```

è¿™å°†çˆ¬å–èµ·å§‹é¡µé¢ä»¥åŠå®ƒç›´æ¥é“¾æ¥çš„é¡µé¢åŠå…¶é“¾æ¥çš„é¡µé¢ï¼ˆæ€»å…± 2 å±‚ï¼‰ã€‚

#### è°ƒæ•´è¯·æ±‚å»¶è¿Ÿï¼š

```bash
node argus.js https://crawler-test.com --delay 2000
```

è¿™å°†åœ¨è¯·æ±‚ä¹‹é—´è®¾ç½® 2 ç§’çš„å»¶è¿Ÿï¼Œå‡å°‘å¯¹ç›®æ ‡ç½‘ç«™çš„å‹åŠ›ã€‚

#### çˆ¬å– crawler-test.com çš„ç‰¹å®šæµ‹è¯•é¡µé¢ï¼š

```bash
# çˆ¬å–åŒ…å«å¤šä¸ªè¡¨æ ¼çš„æµ‹è¯•é¡µé¢
node argus.js https://crawler-test.com/tables --format xlsx

# çˆ¬å–åŒ…å«å„ç§é“¾æ¥ç±»å‹çš„é¡µé¢
node argus.js https://crawler-test.com/links/simple --depth 2

# çˆ¬å–åŒ…å«å›¾ç‰‡çš„é¡µé¢å¹¶ä¸‹è½½èµ„æº
node argus.js https://crawler-test.com/image_jpeg --download-resources
```

#### å¯ç”¨é«˜çº§æ€§èƒ½æ¨¡å¼ï¼š

```bash
node argus.js https://crawler-test.com --advanced-mode
```

å¯ç”¨é«˜çº§æ€§èƒ½æ¨¡å¼ï¼Œæä¾›æ›´é«˜æ•ˆçš„çˆ¬å–å’Œæ›´å¼ºçš„éšç§ä¿æŠ¤ã€‚

### ğŸ”’ é«˜çº§æ€§èƒ½æ¨¡å¼

é«˜çº§æ€§èƒ½æ¨¡å¼ï¼ˆ`--advanced-mode`ï¼‰æ˜¯ä¸ºéœ€è¦æ›´é«˜æ•ˆçˆ¬å–å’Œæ›´å¼ºéšç§ä¿æŠ¤çš„ç”¨æˆ·è®¾è®¡çš„ï¼Œå®ƒæœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

- **æ›´é«˜çš„å¹¶å‘**ï¼šé»˜è®¤å¹¶å‘è¯·æ±‚æ•°ä» 10 å¢åŠ åˆ° 25
- **æ›´å¹¿çš„è¦†ç›–**ï¼šé»˜è®¤æœ€å¤§è¯·æ±‚æ•°ä» 1000 å¢åŠ åˆ° 5000
- **æ›´é•¿çš„è€å¿ƒ**ï¼šé¡µé¢å¯¼èˆªè¶…æ—¶ä» 60 ç§’å¢åŠ åˆ° 120 ç§’
- **å¢å¼ºçš„éšåŒ¿**ï¼šé‡‡ç”¨æ›´å¤šæµè§ˆå™¨æŒ‡çº¹ä¼ªé€ æŠ€æœ¯
- **å¢å¼ºçš„ä»£ç†ä½¿ç”¨**ï¼šæ›´æ™ºèƒ½çš„ä»£ç†è½®æ¢å’Œæ•…éšœè½¬ç§»
- **æ›´å¼ºçš„å†…å®¹æŠ“å–**ï¼šæ”¹è¿›çš„èµ„æºæå–å’Œå¤„ç†èƒ½åŠ›
- **éšæœºåŒ–**ï¼šéšæœºåŒ–è§†å£å¤§å°ã€è¯·æ±‚å¤´ç­‰å‚æ•°

ä½¿ç”¨é«˜çº§æ¨¡å¼æ—¶ï¼Œè¯·è€ƒè™‘ä»¥ä¸‹å»ºè®®ï¼š

1. å¼ºçƒˆå»ºè®®ä½¿ç”¨ä»£ç†åˆ—è¡¨ï¼ˆ`--proxies`ï¼‰
2. è€ƒè™‘ä½¿ç”¨ä»£ç†æµ‹è¯•åŠŸèƒ½ï¼ˆ`--test-proxies`ï¼‰ç¡®ä¿ä»£ç†çš„æœ‰æ•ˆæ€§
3. å¦‚æœç›®æ ‡ç½‘ç«™è´Ÿè½½æ•æ„Ÿï¼Œå¯ä»¥é€‚å½“å¢åŠ å»¶è¿Ÿï¼ˆ`--delay`ï¼‰
4. æ³¨æ„éµå®ˆç½‘ç«™æ¡æ¬¾å’Œå½“åœ°æ³•å¾‹æ³•è§„

### ğŸ“Š å·¥ä½œåŸç†

Argus ä½¿ç”¨ä»¥ä¸‹æŠ€æœ¯å®ç°å¼ºå¤§çš„çˆ¬å–åŠŸèƒ½ï¼š

1. **PlaywrightCrawler**ï¼šå¤„ç†é¡µé¢æ¸²æŸ“å’Œå¯¼èˆª
2. **Puppeteer + Stealth æ’ä»¶**ï¼šç»•è¿‡åçˆ¬è™«æ£€æµ‹
3. **ä»£ç†å’Œç”¨æˆ·ä»£ç†è½®æ¢**ï¼šéšè—çœŸå® IP
4. **æ™ºèƒ½å†…å®¹åˆ†æ**ï¼šæ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©åˆé€‚çš„ä¿å­˜æ ¼å¼
5. **é˜Ÿåˆ—ç®¡ç†**ï¼šé«˜æ•ˆå¤„ç†å¤§é‡é¡µé¢è¯·æ±‚
6. **é”™è¯¯å¤„ç†**ï¼šè‡ªåŠ¨é‡è¯•å¤±è´¥çš„è¯·æ±‚

### ğŸ“ è¾“å‡ºæ–‡ä»¶ç»„ç»‡

çˆ¬å–çš„å†…å®¹å°†æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç»„ç»‡ï¼š

```
output_dir/
â”œâ”€â”€ crawler-test.com/
â”‚   â”œâ”€â”€ tables/
â”‚   â”‚   â”œâ”€â”€ nested.md
â”‚   â”‚   â””â”€â”€ nested.xlsx
â”‚   â”œâ”€â”€ links/
â”‚   â”‚   â””â”€â”€ simple.md
â”‚   â””â”€â”€ index.md
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ crawler.log
â””â”€â”€ downloads/
    â””â”€â”€ images/
        â””â”€â”€ sample.jpg
```

### ğŸ“Š æˆªå›¾ç¤ºä¾‹

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹æˆªå›¾</summary>

#### å‘½ä»¤è¡Œè¾“å‡º
![å‘½ä»¤è¡Œè¾“å‡º](https://via.placeholder.com/800x300/222222/FFFFFF?text=å‘½ä»¤è¡Œè¾“å‡º)

#### Markdownè¾“å‡ºç¤ºä¾‹
![Markdownç»“æœ](https://via.placeholder.com/800x300/333333/FFFFFF?text=Markdownç»“æœ)

#### XLSXè¾“å‡ºç¤ºä¾‹
![XLSXç»“æœ](https://via.placeholder.com/800x300/444444/FFFFFF?text=XLSXç»“æœ)

</details>

### ğŸ”§ é—®é¢˜æ’æŸ¥

#### æµè§ˆå™¨åˆå§‹åŒ–é—®é¢˜

å¦‚æœé‡åˆ°æµè§ˆå™¨åˆå§‹åŒ–é—®é¢˜ï¼š

1. ç¡®ä¿å®‰è£…äº†Playwrightçš„æµè§ˆå™¨ï¼š`npx playwright install`
2. åœ¨Linuxä¸Šï¼Œå®‰è£…ç³»ç»Ÿä¾èµ–ï¼š`npx playwright install-deps`
3. å¦‚æœæ‚¨å·²ç»åœ¨è‡ªå®šä¹‰ä½ç½®å®‰è£…äº†æµè§ˆå™¨ï¼Œè¯·å°è¯•ä½¿ç”¨`--no-browser-check`æ ‡å¿—
4. æ£€æŸ¥æ‚¨çš„ç³»ç»Ÿæ˜¯å¦æ»¡è¶³Playwrightçš„è¦æ±‚

#### ä»£ç†é—®é¢˜

å¦‚æœæ‚¨åœ¨ä½¿ç”¨ä»£ç†æ—¶é‡åˆ°é—®é¢˜ï¼š

1. éªŒè¯ä»£ç†æ ¼å¼ï¼ˆä¾‹å¦‚ï¼Œ`http://user:pass@hostname:port`ï¼‰
2. ä½¿ç”¨`--test-proxies`æ ‡å¿—åœ¨çˆ¬å–å‰éªŒè¯ä»£ç†
3. ç¡®ä¿æ‚¨æœ‰æƒé™ä½¿ç”¨è¿™äº›ä»£ç†
4. æ£€æŸ¥ä»æ‚¨çš„æœºå™¨åˆ°ä»£ç†çš„ç½‘ç»œè¿æ¥

#### å†…å®¹æœªæ­£ç¡®ä¿å­˜

å¦‚æœå†…å®¹æå–æœªæŒ‰é¢„æœŸå·¥ä½œï¼š

1. æ£€æŸ¥ç›®æ ‡ç½‘ç«™æ˜¯å¦ä½¿ç”¨ä¸å¸¸è§çš„æ ‡è®°ç»“æ„
2. å°è¯•ä¸åŒçš„è¾“å‡ºæ ¼å¼ï¼ˆ`--format markdown`æˆ–`--format xlsx`ï¼‰
3. å¯¹äºå¤æ‚é¡µé¢ï¼Œå¢åŠ å¯¼èˆªè¶…æ—¶ï¼ˆ`--navigation-timeout 120000`ï¼‰
4. ä½¿ç”¨`--debug`æ ‡å¿—æŸ¥çœ‹è¯¦ç»†æ—¥å¿—è¿›è¡Œè°ƒè¯•

### ğŸ¤ å‚ä¸è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼è¯·éšæ—¶æäº¤Pull Requestã€‚

1. Forkæ­¤ä»“åº“
2. åˆ›å»ºæ‚¨çš„åŠŸèƒ½åˆ†æ”¯ï¼ˆ`git checkout -b feature/amazing-feature`ï¼‰
3. æäº¤æ‚¨çš„æ›´æ”¹ï¼ˆ`git commit -am 'Add some amazing feature'`ï¼‰
4. æ¨é€åˆ°åˆ†æ”¯ï¼ˆ`git push origin feature/amazing-feature`ï¼‰
5. åˆ›å»ºæ–°çš„Pull Request

è¯·é˜…è¯»[CONTRIBUTING.md](CONTRIBUTING.md)äº†è§£æˆ‘ä»¬çš„è¡Œä¸ºå‡†åˆ™å’Œæäº¤Pull Requestçš„æµç¨‹ã€‚

### âš ï¸ æ³¨æ„äº‹é¡¹

ä½¿ç”¨ Argus æ—¶ï¼Œè¯·ï¼š

- å°Šé‡ç›®æ ‡ç½‘ç«™çš„æœåŠ¡æ¡æ¬¾
- éµå®ˆå½“åœ°æ³•å¾‹æ³•è§„
- ä¸è¦å¯¹ç›®æ ‡ç½‘ç«™é€ æˆè¿‡å¤§è´Ÿè½½
- ä»…ç”¨äºåˆæ³•ç›®çš„ï¼Œå¦‚æ•°æ®åˆ†æå’Œç ”ç©¶

ä½¿ç”¨é«˜çº§æ€§èƒ½æ¨¡å¼æ—¶è¯·æ ¼å¤–æ³¨æ„ä¸Šè¿°äº‹é¡¹ã€‚

### ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - è¯¦æƒ…è¯·å‚é˜…[LICENSE](LICENSE)æ–‡ä»¶ã€‚

---

<a id="english"></a>

## ğŸŒ English

Argus is a powerful automated web crawler tool that can bypass anti-crawler protection, protect the privacy of the crawler, and convert content to Markdown or XLSX formats.

### âš¡ Quick Start

#### Method 1: Direct Installation

```bash
# Clone repository or download the project
git clone https://github.com/BreCaspian/argus-crawler.git
cd argus-crawler

# Install dependencies
npm install

# Basic usage
node argus.js https://example.com
```

#### Method 2: Using npm CLI

```bash
# Install globally via npm
npm install -g argus-crawler

# Basic usage
argus https://example.com

# Advanced mode with proxy
argus https://example.com --advanced-mode --proxies proxies.txt
```

### âœ¨ Features

- **Automated Crawling**: Just input the starting URL and automatically crawl the entire website
- **Anti-Crawler Technology**: Automatically bypass JavaScript challenges, CAPTCHAs, and browser fingerprint detection
- **IP Protection**: Support proxy rotation and user agent rotation to avoid being banned
- **Smart Content Extraction**: Automatically extract the main content of the page and filter out noise
- **Multiple Output Formats**: Automatically select the appropriate format (Markdown, XLSX, or mixed) based on content characteristics
- **Structured Storage**: Organize files according to website architecture for easy retrieval and management
- **Privacy Protection**: Encrypted logging to protect user privacy
- **Advanced Performance Mode**: Provides higher performance crawling options and enhanced anonymity
- **Cross-Platform Support**: Compatible with Windows, macOS, and Linux operating systems

### ğŸ“„ Project Architecture

```
argus-crawler/
â”œâ”€â”€ src/                      # Core source code
â”‚   â”œâ”€â”€ ArgusCrawler.js       # Main crawler implementation
â”‚   â”œâ”€â”€ ProxyManager.js       # Proxy management and rotation
â”‚   â””â”€â”€ utils.js              # Utility functions
â”œâ”€â”€ scripts/                  # Support scripts
â”‚   â””â”€â”€ browser-setup.js      # Browser environment setup
â”œâ”€â”€ examples/                 # Usage examples
â”‚   â””â”€â”€ basic-usage.js        # Basic demo
â”œâ”€â”€ tests/                    # Test files
â”‚   â””â”€â”€ basic.test.js         # Core functionality tests
â”œâ”€â”€ argus.js                  # Main executable
â”œâ”€â”€ package.json              # Project metadata
â”œâ”€â”€ README.md                 # Documentation
â””â”€â”€ LICENSE                   # MIT License
```

### ğŸš€ Installation

#### Prerequisites

- Node.js 16.x or higher
- npm or yarn package manager

#### Installation Method

**Clone from GitHub**

```bash
git clone https://github.com/BreCaspian/argus-crawler.git
cd argus-crawler
npm install
```

#### Browser Engine Installation

Argus uses Playwright as its browser engine. After installing dependencies, the system will automatically try to install the required browsers. If automatic installation fails, you can install manually:

```bash
# Install all supported browsers
npx playwright install

# Only install Chromium (recommended, smaller footprint)
npx playwright install chromium
   
# On Linux, you may need additional system dependencies
npx playwright install-deps
```

#### Make the tool executable (Linux/macOS only)

```bash
chmod +x argus.js
```

### ğŸ–¥ï¸ Cross-Platform Usage

Argus is fully compatible with all major operating systems:

- **Windows**:
  ```
  node argus.js <url> [options]
  ```

- **macOS**:
  ```
  ./argus.js <url> [options]
  # or
  node argus.js <url> [options]
  ```

- **Linux**:
  ```
  ./argus.js <url> [options]
  # or
  node argus.js <url> [options]
  ```

#### Platform-Specific Notes

- **Windows**: On Windows, the tool automatically detects and uses the appropriate browser paths
- **macOS**: On macOS, additional permissions might be required to access certain system directories
- **Linux**: On Linux systems, additional dependencies might be needed for browser automation. Use `npx playwright install-deps` to install required system packages

### ğŸ“– Basic Usage

The simplest usage is to directly provide the target website URL:

```bash
node argus.js https://crawler-test.com
```

This will crawl the website using default settings and save the results in the `argus_data` folder in the current directory.

### ğŸ› ï¸ Command Line Options

| Option | Short | Description | Default |
|--------|-------|-------------|---------|
| `--output-dir <path>` | `-o` | Specify output directory | `./argus_data` |
| `--proxies <file>` | `-p` | Specify proxy list file | None |
| `--depth <number>` | `-d` | Set crawl depth (1 means only crawl the starting page and its direct links) | `1` |
| `--delay <ms>` | `-w` | Delay between requests (milliseconds) | `1000` |
| `--format <format>` | `-f` | Output format (markdown/xlsx/html/auto) | `auto` |
| `--encrypt` | `-e` | Encrypt output content | `false` |
| `--key <key>` | `-k` | Encryption/decryption key | `argus-default-key` |
| `--advanced-mode` | `-a` | Enable advanced performance mode | `false` |
| `--test-proxies` | N/A | Test proxy validity before use | `false` |
| `--max-concurrency <number>` | N/A | Maximum concurrent requests | `10` (standard) / `25` (advanced) |
| `--max-requests <number>` | N/A | Maximum total requests | `1000` (standard) / `5000` (advanced) |
| `--navigation-timeout <ms>` | N/A | Page navigation timeout (milliseconds) | `60000` (standard) / `120000` (advanced) |
| `--no-browser-check` | N/A | Skip browser dependency check | `false` |
| `--download-resources` | N/A | Download page resources (images, etc.) | `false` |
| `--max-file-size <MB>` | N/A | Maximum file size for downloaded resources (MB) | `10` |
| `--help`, `-h` | N/A | Display help information | N/A |
| `--version`, `-v` | N/A | Display version number | N/A |

### ğŸ§° Special Commands

Argus also provides some special commands:

```bash
# Test environment and dependencies
node argus.js test-env

# Decrypt encrypted files
node argus.js decrypt <encrypted_file> --key <key> --output <output_file>
```

### ğŸ“ Usage Examples

#### Using a proxy list:

```bash
node argus.js https://crawler-test.com --proxies proxies.txt
```

The proxy file should contain one proxy server address per line, e.g., `http://123.45.67.89:8080`.

#### Limiting crawl depth:

```bash
node argus.js https://crawler-test.com --depth 2
```

This will crawl the starting page plus its linked pages and their linked pages (2 levels in total).

#### Adjusting request delay:

```bash
node argus.js https://crawler-test.com --delay 2000
```

This sets a 2-second delay between requests, reducing pressure on the target website.

#### Crawling specific test pages on crawler-test.com:

```bash
# Crawl test page with multiple tables
node argus.js https://crawler-test.com/tables --format xlsx

# Crawl page with various link types
node argus.js https://crawler-test.com/links/simple --depth 2

# Crawl page with images and download resources
node argus.js https://crawler-test.com/image_jpeg --download-resources
```

#### Enabling advanced performance mode:

```bash
node argus.js https://crawler-test.com --advanced-mode
```

Enable advanced performance mode for more efficient crawling and stronger privacy protection.

### ğŸ”’ Advanced Performance Mode

Advanced performance mode (`--advanced-mode`) is designed for users who need more efficient crawling and stronger privacy protection. It offers:

- **Higher concurrency**: Default concurrent requests increased from 10 to 25
- **Broader coverage**: Default maximum requests increased from 1000 to 5000
- **Longer patience**: Page navigation timeout increased from 60 seconds to 120 seconds
- **Enhanced stealth**: More browser fingerprint spoofing techniques
- **Enhanced proxy usage**: Smarter proxy rotation and failover
- **Stronger content extraction**: Improved resource extraction and processing capabilities
- **Randomization**: Randomize viewport sizes, request headers, and other parameters

When using advanced mode, consider these recommendations:

1. Strongly recommended to use a proxy list (`--proxies`)
2. Consider using the proxy testing feature (`--test-proxies`) to ensure proxy validity
3. Adjust the delay (`--delay`) if the target website is load-sensitive
4. Be mindful of the website's terms of service and local laws and regulations

### ğŸ“Š How It Works

Argus uses the following technologies to achieve powerful crawling capabilities:

1. **PlaywrightCrawler**: Handles page rendering and navigation
2. **Puppeteer + Stealth plugins**: Bypasses anti-crawler detection
3. **Proxy and user agent rotation**: Hides real IP
4. **Intelligent content analysis**: Chooses appropriate saving format based on content type
5. **Queue management**: Efficiently processes large numbers of page requests
6. **Error handling**: Automatically retries failed requests

### ğŸ“ Output File Organization

The crawled content will be organized according to the following structure:

```
output_dir/
â”œâ”€â”€ crawler-test.com/
â”‚   â”œâ”€â”€ tables/
â”‚   â”‚   â”œâ”€â”€ nested.md
â”‚   â”‚   â””â”€â”€ nested.xlsx
â”‚   â”œâ”€â”€ links/
â”‚   â”‚   â””â”€â”€ simple.md
â”‚   â””â”€â”€ index.md
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ crawler.log
â””â”€â”€ downloads/
    â””â”€â”€ images/
        â””â”€â”€ sample.jpg
```

### ğŸ“Š Screenshot Examples

<details>
<summary>Click to view screenshots</summary>

#### Command Line Output
![Command Line Output](https://via.placeholder.com/800x300/222222/FFFFFF?text=Command+Line+Output)

#### Markdown Output Example
![Markdown Result](https://via.placeholder.com/800x300/333333/FFFFFF?text=Markdown+Result)

#### XLSX Output Example
![XLSX Result](https://via.placeholder.com/800x300/444444/FFFFFF?text=XLSX+Result)

</details>

### ğŸ”§ Troubleshooting

#### Browser Initialization Problems

If you encounter browser initialization problems:

1. Ensure Playwright's browsers are installed: `npx playwright install`
2. On Linux, install system dependencies: `npx playwright install-deps`
3. Try running with `--no-browser-check` flag if you've already installed browsers in a custom location
4. Check if your system meets Playwright's requirements

#### Proxy Issues

If you're having trouble with proxies:

1. Verify proxy format (e.g., `http://user:pass@hostname:port`)
2. Use the `--test-proxies` flag to validate proxies before crawling
3. Ensure you have permission to use the proxies
4. Check network connectivity from your machine to the proxies

#### Content Not Being Saved Correctly

If content extraction doesn't work as expected:

1. Check if the target website uses unusual markup structures
2. Try different output formats (`--format markdown` or `--format xlsx`)
3. Increase the navigation timeout for complex pages (`--navigation-timeout 120000`)
4. For debugging, use `--debug` flag to see detailed logs

### ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -am 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Create a new Pull Request

Please read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.

### âš ï¸ Notice

When using Argus, please:

- Respect the target website's terms of service
- Comply with local laws and regulations
- Do not cause excessive load on the target website
- Use only for legitimate purposes such as data analysis and research

Be especially mindful of these considerations when using advanced performance mode.

### ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details. 